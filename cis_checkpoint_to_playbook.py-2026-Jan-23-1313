#!/usr/bin/env python3
"""
CIS Checkpoint to Ansible Playbook Generator

This script:
1. Queries the CIS RHEL 8 Benchmark using RAG to get checkpoint audit info
2. Uses DeepSeek AI to generate playbook requirements based on the checkpoint
3. Generates an Ansible playbook to audit the CIS checkpoint
4. Optionally executes the playbook on the target host

Usage:
    python3 cis_checkpoint_to_playbook.py --checkpoint "1.1.1.1"
    python3 cis_checkpoint_to_playbook.py --checkpoint "1.1.1.1 Ensure cramfs kernel module is not available" --target-host 192.168.122.16
"""

import os
import sys
import json
import argparse
import subprocess
from pathlib import Path
from dotenv import load_dotenv

load_dotenv()

# =============================================================================
# Vector Store Setup (from cis_rhel8_rag_deepseek.py)
# =============================================================================

from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma

# Configuration - Use same directory as cis_rhel8_rag_deepseek.py
VECTOR_STORE_DIR = Path(__file__).parent / "CIS_RHEL8_DATA_DEEPSEEK"
PDF_PATH = "resources/CIS_Red_Hat_Enterprise_Linux_8_Benchmark_v4.0.0.pdf"

# Use HuggingFace embeddings (same as cis_rhel8_rag_deepseek.py)
embeddings = HuggingFaceEmbeddings(
    model_name="sentence-transformers/all-MiniLM-L6-v2",
    model_kwargs={'device': 'cpu'},
    encode_kwargs={'normalize_embeddings': True}
)

def load_or_create_vector_store():
    """Load existing vector store or create new one from PDF."""
    
    if (VECTOR_STORE_DIR / "chroma.sqlite3").exists():
        print(f"Loading existing vector store from {VECTOR_STORE_DIR}...")
        vector_store = Chroma(
            persist_directory=str(VECTOR_STORE_DIR),
            embedding_function=embeddings
        )
        doc_count = vector_store._collection.count()
        print(f"Vector store loaded with {doc_count} documents")
        
        if doc_count == 0:
            print("‚ö†Ô∏è  WARNING: Vector store exists but has 0 documents!")
            print("    Deleting empty vector store and recreating...")
            import shutil
            shutil.rmtree(VECTOR_STORE_DIR)
            VECTOR_STORE_DIR.mkdir(parents=True, exist_ok=True)
        else:
            # Test search to verify it works
            try:
                test_results = vector_store.similarity_search("CIS benchmark", k=1)
                if test_results:
                    print(f"‚úÖ Vector store verified - test search returned results")
                else:
                    print("‚ö†Ô∏è  WARNING: Test search returned no results")
            except Exception as e:
                print(f"‚ö†Ô∏è  WARNING: Test search failed: {e}")
            return vector_store
    
    # Create new vector store from PDF
    print("No existing vector store found. Creating from PDF...")
    
    from langchain_community.document_loaders import PyPDFLoader
    from langchain_text_splitters import RecursiveCharacterTextSplitter
    
    print(f"Loading CIS RHEL 8 Benchmark PDF from {PDF_PATH}...")
    loader = PyPDFLoader(PDF_PATH)
    data = loader.load()
    print(f"Loaded {len(data)} pages from CIS benchmark document")
    
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1500, chunk_overlap=300, add_start_index=True
    )
    all_splits = text_splitter.split_documents(data)
    print(f"Created {len(all_splits)} document chunks")
    
    print(f"Building and persisting vector store to {VECTOR_STORE_DIR}...")
    vector_store = Chroma.from_documents(
        documents=all_splits,
        embedding=embeddings,
        persist_directory=str(VECTOR_STORE_DIR)
    )
    print("Vector store created and saved")
    
    return vector_store


# =============================================================================
# CIS Checkpoint Search - Using Agent-based RAG (like cis_rhel8_rag_deepseek.py)
# =============================================================================

def create_cis_search_tool(vector_store):
    """Create a search tool for the CIS benchmark vector store."""
    from langchain_core.tools import tool
    
    @tool
    def search_cis_benchmark(query: str) -> str:
        """Search the CIS RHEL 8 Benchmark document for security control information.
        
        Use this tool to find:
        - Audit procedures for specific CIS controls
        - Remediation steps for security configurations
        - Profile applicability (Level 1/Level 2, Server/Workstation)
        - Rationale for security recommendations
        
        Args:
            query: The CIS control number (e.g., '1.1.1.1') or description to search for
        """
        results = vector_store.similarity_search(query, k=4)
        # Combine top results for more comprehensive context
        combined_content = "\n\n---\n\n".join([doc.page_content for doc in results])
        return combined_content
    
    return search_cis_benchmark


def get_checkpoint_info_with_agent(vector_store, checkpoint: str, verbose: bool = False) -> dict:
    """
    Use an agent-based RAG approach to get checkpoint information.
    This mirrors the approach in cis_rhel8_rag_deepseek.py which works better.
    
    Args:
        vector_store: The Chroma vector store
        checkpoint: The CIS checkpoint ID/description
        verbose: If True, print debug information
        
    Returns:
        dict: Structured checkpoint information
    """
    from langchain_openai import ChatOpenAI
    from langchain.agents import create_agent
    from langchain_core.messages import HumanMessage
    
    # Create the search tool
    search_tool = create_cis_search_tool(vector_store)
    
    # Create the LLM
    llm = ChatOpenAI(
        model="deepseek-chat",
        api_key=os.getenv("DEEPSEEK_API_KEY"),
        base_url="https://api.deepseek.com",
        temperature=0
    )
    
    # Create agent with system prompt optimized for extracting structured info
    system_prompt = """You are a CIS RHEL 8 security expert. Your task is to find and extract detailed information about a specific CIS checkpoint.

When asked about a checkpoint:
1. Use the search tool to find information about the checkpoint
2. Search multiple times if needed - try different queries like:
   - The checkpoint number (e.g., "1.1.1.2")
   - The checkpoint with "Ensure" (e.g., "1.1.1.2 Ensure")
   - Keywords from the checkpoint (e.g., "freevxfs kernel module")
3. Extract ALL relevant information including:
   - Profile Applicability (Level 1/Level 2, Server/Workstation)
   - Description
   - Rationale
   - Audit procedure (exact commands)
   - Remediation procedure (exact commands)
   - Impact
   - Default Value

Be thorough and search multiple times to find complete information."""

    agent = create_agent(
        model=llm,
        tools=[search_tool],
        system_prompt=system_prompt
    )
    
    # Query the agent for checkpoint information
    query = f"""Find and extract ALL information about CIS checkpoint {checkpoint}.

I need the following in your response (use the search tool multiple times if needed):
1. Checkpoint ID (exact number like 1.1.1.2)
2. Title (e.g., "Ensure freevxfs kernel module is not available")
3. Profile Applicability (Level 1 or Level 2, Server or Workstation)
4. Description (what this control does)
5. Rationale (why this is important for security)
6. COMPLETE Audit procedure (include ALL shell commands exactly as shown)
7. COMPLETE Remediation procedure (include ALL shell commands exactly as shown)
8. Impact (if any)
9. Default Value (if mentioned)

Search for "{checkpoint}" and related terms to find all the details."""

    if verbose:
        print(f"üîç DEBUG: Querying agent for checkpoint: {checkpoint}")
    
    response = agent.invoke(
        {"messages": [HumanMessage(content=query)]}
    )
    
    # Get the agent's response
    agent_response = response["messages"][-1].content
    
    if verbose:
        print(f"üîç DEBUG: Agent response length: {len(agent_response)} characters")
        print("\n" + "-"*50 + " AGENT RESPONSE " + "-"*50)
        print(agent_response[:3000] if len(agent_response) > 3000 else agent_response)
        print("-"*120 + "\n")
    
    return agent_response


def search_cis_checkpoint(vector_store, checkpoint: str, verbose: bool = False) -> str:
    """
    Search the CIS RHEL 8 Benchmark for checkpoint information.
    Falls back to direct search if agent approach fails.
    
    Args:
        vector_store: The Chroma vector store
        checkpoint: The CIS control number or description
        verbose: If True, print raw search results for debugging
        
    Returns:
        str: Combined content from relevant documents
    """
    import re
    
    # Extract checkpoint ID if present (e.g., "1.1.1.1" from "1.1.1.1 Ensure cramfs...")
    checkpoint_id_match = re.match(r'^(\d+\.\d+\.\d+\.?\d*)', checkpoint)
    checkpoint_id = checkpoint_id_match.group(1) if checkpoint_id_match else checkpoint
    
    # Build multiple search queries for better coverage
    enhanced_queries = []
    
    # Primary queries - most specific
    if checkpoint_id_match:
        enhanced_queries.extend([
            f"{checkpoint_id} Ensure",
            f"checkpoint {checkpoint_id}",
            f"{checkpoint_id} kernel module",
            f"{checkpoint_id} freevxfs",  # Common for 1.1.1.x
            f"{checkpoint_id} Audit",
            f"{checkpoint_id} Remediation",
        ])
    
    # Add the original query
    enhanced_queries.append(checkpoint)
    
    # Generic CIS-related queries
    enhanced_queries.extend([
        f"CIS {checkpoint_id}" if checkpoint_id_match else f"CIS {checkpoint}",
        f"Profile Applicability {checkpoint_id}" if checkpoint_id_match else checkpoint,
    ])
    
    # Remove duplicates while preserving order
    seen = set()
    unique_queries = []
    for q in enhanced_queries:
        if q not in seen:
            seen.add(q)
            unique_queries.append(q)
    
    if verbose:
        print(f"\nüîç DEBUG: Checkpoint ID extracted: {checkpoint_id}")
        print(f"üîç DEBUG: Search queries to try: {unique_queries}")
    
    # Collect results from multiple queries
    all_results = []
    seen_content = set()
    
    for query in unique_queries:
        try:
            results = vector_store.similarity_search(query, k=4)
            if verbose:
                print(f"üîç DEBUG: Query '{query}' returned {len(results)} results")
            for doc in results:
                # Deduplicate by content hash (use more of the content for better dedup)
                content_hash = hash(doc.page_content[:500])
                if content_hash not in seen_content:
                    seen_content.add(content_hash)
                    all_results.append(doc)
        except Exception as e:
            if verbose:
                print(f"üîç DEBUG: Query '{query}' failed: {e}")
    
    # Sort results by relevance to checkpoint_id (if found in content)
    def relevance_score(doc):
        content = doc.page_content.lower()
        score = 0
        if checkpoint_id.lower() in content:
            score += 10
        if "ensure" in content and checkpoint_id.lower() in content:
            score += 5
        if "audit" in content:
            score += 2
        if "remediation" in content:
            score += 2
        return -score  # Negative for descending sort
    
    all_results.sort(key=relevance_score)
    
    # Limit to top 10 unique results
    all_results = all_results[:10]
    
    combined_content = "\n\n---\n\n".join([doc.page_content for doc in all_results])
    
    if verbose:
        print(f"\nüîç DEBUG: Total unique document chunks found: {len(all_results)}")
        print(f"üîç DEBUG: Combined content length: {len(combined_content)} characters")
        print("\n" + "-"*50 + " RAW CONTENT PREVIEW " + "-"*50)
        # Show full content in verbose mode
        print(combined_content[:5000] if len(combined_content) > 5000 else combined_content)
        print("-"*120 + "\n")
    
    # Always show a warning if no content found
    if len(combined_content) < 100:
        print("‚ö†Ô∏è  WARNING: Very little content retrieved from vector store!")
        print("    Make sure CIS_RHEL8_DATA_DEEPSEEK directory has the vector database.")
        print("    You may need to run cis_rhel8_rag_deepseek.py first to create the vector store.")
    
    return combined_content


def parse_agent_response_to_checkpoint_info(checkpoint: str, agent_response: str) -> dict:
    """
    Parse the agent's natural language response into a structured dictionary.
    
    Args:
        checkpoint: The original checkpoint query
        agent_response: The agent's response text
        
    Returns:
        dict: Structured checkpoint information
    """
    import re
    
    # Initialize with defaults
    info = {
        'checkpoint_id': checkpoint,
        'title': '',
        'profile_applicability': '',
        'description': '',
        'rationale': '',
        'audit_procedure': '',
        'remediation_procedure': '',
        'impact': '',
        'default_value': '',
        'references': ''
    }
    
    # Extract checkpoint ID from response
    id_match = re.search(r'(\d+\.\d+\.\d+\.?\d*)', agent_response)
    if id_match:
        info['checkpoint_id'] = id_match.group(1)
    
    # Helper function to extract section content
    def extract_section(text, section_names, next_sections=None):
        """Extract content between section header and next section."""
        for name in section_names:
            # Try different patterns
            patterns = [
                rf'\*\*{name}\*\*[:\s]*\n?(.*?)(?=\*\*[A-Z]|\n\n\n|$)',
                rf'{name}[:\s]*\n(.*?)(?=\n[A-Z][a-z]+:|$)',
                rf'#{1,3}\s*{name}[:\s]*\n?(.*?)(?=#{1,3}|$)',
            ]
            for pattern in patterns:
                match = re.search(pattern, text, re.IGNORECASE | re.DOTALL)
                if match and match.group(1).strip():
                    return match.group(1).strip()
        return ''
    
    # Extract title
    title_patterns = [
        rf'{info["checkpoint_id"]}[:\s]*(Ensure[^\n]+)',
        r'\*\*Title\*\*[:\s]*([^\n]+)',
        r'Title[:\s]*([^\n]+)',
    ]
    for pattern in title_patterns:
        match = re.search(pattern, agent_response, re.IGNORECASE)
        if match:
            info['title'] = match.group(1).strip()
            break
    
    # If no title found, try to extract from first line mentioning "Ensure"
    if not info['title']:
        ensure_match = re.search(r'(Ensure[^\n\.]+)', agent_response)
        if ensure_match:
            info['title'] = ensure_match.group(1).strip()
    
    # Extract other sections
    info['profile_applicability'] = extract_section(
        agent_response, 
        ['Profile Applicability', 'Profile', 'Applicability']
    )
    
    info['description'] = extract_section(
        agent_response,
        ['Description']
    )
    
    info['rationale'] = extract_section(
        agent_response,
        ['Rationale', 'Why', 'Security Rationale']
    )
    
    info['audit_procedure'] = extract_section(
        agent_response,
        ['Audit', 'Audit Procedure', 'How to Audit', 'Audit Commands']
    )
    
    info['remediation_procedure'] = extract_section(
        agent_response,
        ['Remediation', 'Remediation Procedure', 'How to Remediate', 'Fix']
    )
    
    info['impact'] = extract_section(
        agent_response,
        ['Impact']
    )
    
    info['default_value'] = extract_section(
        agent_response,
        ['Default Value', 'Default']
    )
    
    # If critical fields are empty, store the full agent response
    if not info['audit_procedure'] or not info['title']:
        info['raw_agent_response'] = agent_response
    
    return info


def get_checkpoint_info_with_ai(checkpoint: str, raw_content: str) -> dict:
    """
    Use DeepSeek AI to extract structured checkpoint information.
    
    Args:
        checkpoint: The CIS checkpoint ID/description
        raw_content: Raw content from vector search
        
    Returns:
        dict: Structured checkpoint information
    """
    from langchain_openai import ChatOpenAI
    from langchain_core.prompts import ChatPromptTemplate
    
    llm = ChatOpenAI(
        model="deepseek-chat",
        api_key=os.getenv("DEEPSEEK_API_KEY"),
        base_url="https://api.deepseek.com",
        temperature=0
    )
    
    prompt_template = """You are a CIS RHEL 8 security expert. Analyze the following content extracted from the CIS Benchmark PDF document and extract structured information about the requested checkpoint.

**Requested Checkpoint:** {checkpoint}

**Raw Content from CIS Benchmark (may contain multiple document chunks):**
{raw_content}

**Task:** 
Carefully read through ALL the raw content above. The information may be split across multiple chunks separated by "---". Look for:
- The checkpoint number (e.g., "1.1.1.1")
- Title starting with "Ensure" or similar
- Sections labeled "Profile Applicability", "Description", "Rationale", "Audit", "Remediation", "Impact", "Default Value", "References"
- Shell commands in the Audit and Remediation sections

Extract and return a JSON object with this structure:
{{
    "checkpoint_id": "The exact checkpoint ID (e.g., 1.1.1.1)",
    "title": "The full title (e.g., 'Ensure cramfs kernel module is not available')",
    "profile_applicability": "Level 1 or Level 2, Server/Workstation (look for 'Profile Applicability' section)",
    "description": "Brief description of what this control does",
    "rationale": "Why this control is important for security (look for 'Rationale' section)",
    "audit_procedure": "The COMPLETE audit commands/steps - include ALL shell commands exactly as shown",
    "remediation_procedure": "The COMPLETE remediation commands/steps - include ALL shell commands exactly as shown",
    "impact": "Any potential impact (look for 'Impact' section)",
    "default_value": "The default system value (look for 'Default Value' section)",
    "references": "Any CIS or other references"
}}

**Critical Instructions:**
1. Search through ALL chunks in the raw content - the information may be spread across multiple sections
2. For audit_procedure and remediation_procedure, include the COMPLETE shell commands exactly as written
3. Look for patterns like "Run the following command" or "# " prefix for commands
4. If a section says "None" or is empty, use that value
5. If information truly cannot be found in any chunk, use "Not found in provided content"
6. Return ONLY valid JSON, no markdown code blocks

Generate the JSON now:"""

    prompt = ChatPromptTemplate.from_template(prompt_template)
    chain = prompt | llm
    
    response = chain.invoke({
        'checkpoint': checkpoint,
        'raw_content': raw_content
    })
    
    response_text = response.content.strip()
    
    # Clean up response - remove markdown code blocks if present
    if "```json" in response_text:
        response_text = response_text.split("```json")[1].split("```")[0].strip()
    elif "```" in response_text:
        response_text = response_text.split("```")[1].split("```")[0].strip()
    
    try:
        result = json.loads(response_text)
        # Check if AI couldn't find the info - fall back to raw content
        not_found_indicators = ['not found', 'not specified', 'unable to find', 'no information']
        fields_not_found = sum(1 for v in result.values() 
                               if isinstance(v, str) and any(ind in v.lower() for ind in not_found_indicators))
        
        if fields_not_found >= 5:  # Most fields not found
            print("‚ö†Ô∏è  AI extraction found limited information. Using raw content as fallback.")
            print("    TIP: Try with full checkpoint description for better results.")
            result['raw_content_preview'] = raw_content[:3000]
            # Try to extract basic info from raw content directly
            import re
            # Look for checkpoint title pattern
            title_match = re.search(rf'{re.escape(checkpoint)}[^\n]*Ensure[^\n]+', raw_content, re.IGNORECASE)
            if title_match:
                result['title'] = title_match.group(0).strip()
            # Look for audit section
            audit_match = re.search(r'Audit[:\s]*\n(.*?)(?=Remediation|$)', raw_content, re.DOTALL | re.IGNORECASE)
            if audit_match:
                result['audit_procedure'] = audit_match.group(1).strip()[:2000]
            # Look for remediation section
            remed_match = re.search(r'Remediation[:\s]*\n(.*?)(?=Impact|Default|References|$)', raw_content, re.DOTALL | re.IGNORECASE)
            if remed_match:
                result['remediation_procedure'] = remed_match.group(1).strip()[:2000]
        return result
    except json.JSONDecodeError as e:
        print(f"Warning: Failed to parse JSON response: {e}")
        print(f"Response was: {response_text[:500]}...")
        return {
            'checkpoint_id': checkpoint,
            'title': 'Unable to parse AI response',
            'audit_procedure': raw_content[:2000],
            'remediation_procedure': 'See raw content above',
            'raw_content_preview': raw_content[:3000]
        }


# =============================================================================
# Playbook Requirements Generation (adapted from kcs_to_playbook.py)
# =============================================================================

def extract_audit_steps_from_procedure(audit_procedure: str, checkpoint_id: str = "", title: str = "") -> list:
    """
    Extract individual audit steps/commands/scripts from the CIS audit procedure text.
    
    Args:
        audit_procedure: The complete audit procedure text from CIS benchmark
        checkpoint_id: The checkpoint ID for context
        title: The checkpoint title (e.g., "Ensure freevxfs kernel module is not available")
        
    Returns:
        list: List of requirement strings extracted from the audit procedure
    """
    import re
    
    requirements = []
    
    if not audit_procedure or len(audit_procedure) < 20:
        return requirements
    
    # Try to extract the module/service name from title or audit procedure
    module_name = ""
    if title:
        # Extract module name from title like "Ensure freevxfs kernel module is not available"
        module_match = re.search(r'(?:Ensure|Verify)\s+(\w+)\s+(?:kernel\s+)?module', title, re.IGNORECASE)
        if module_match:
            module_name = module_match.group(1)
    
    if not module_name:
        # Try to find module name from audit procedure (look for lsmod | grep <module>)
        module_match = re.search(r"lsmod\s*\|\s*grep\s+['\"]?(\w+)['\"]?", audit_procedure, re.IGNORECASE)
        if module_match:
            module_name = module_match.group(1)
    
    # Pattern 1: Check for audit script existence and add script-based requirement
    has_script = '#!/' in audit_procedure or 'l_output=' in audit_procedure or 'l_mname=' in audit_procedure
    
    if has_script and module_name:
        requirements.append(
            f"Check if the {module_name} kernel module is available on the filesystem using the provided audit script. "
            f"Rationale: PASS (module not available) when the script returns no output or module is built into kernel, "
            f"FAIL (module available) when the script returns a path indicating the module exists as a loadable .ko file."
        )
    elif has_script:
        requirements.append(
            f"Run the CIS audit script to check system compliance. "
            f"Rationale: PASS when script output indicates compliance (l_output has results, l_output2 is empty), "
            f"FAIL when script reports non-compliance (l_output2 has errors)."
        )
    
    # Pattern 2: Extract lsmod command for checking loaded modules
    lsmod_match = re.search(r"lsmod\s*\|\s*grep\s+['\"]?(\w+)['\"]?", audit_procedure, re.IGNORECASE)
    if lsmod_match:
        mod = lsmod_match.group(1)
        requirements.append(
            f"Verify the {mod} kernel module is not currently loaded using command: `lsmod | grep '{mod}'`. "
            f"Rationale: PASS (not loaded) when the command returns no output (exit code 1), "
            f"FAIL (loaded) when '{mod}' appears in the output (exit code 0)."
        )
    
    # Pattern 3: Extract modprobe --showconfig command
    modprobe_match = re.search(r"modprobe\s+--showconfig\s*\|\s*grep[^\n]+", audit_procedure, re.IGNORECASE)
    if modprobe_match:
        cmd = modprobe_match.group(0).strip()
        mod = module_name or "the module"
        requirements.append(
            f"Verify the {mod} kernel module is configured to be non-loadable by checking modprobe configuration "
            f"using command: `{cmd}`. "
            f"Rationale: PASS (blacklisted) when output contains 'blacklist {mod}' and 'install {mod} /bin/false' or '/bin/true', "
            f"FAIL (not blacklisted) when these entries are missing."
        )
    
    # Pattern 4: Extract other specific commands
    cmd_patterns = [
        (r'systemctl\s+(?:is-enabled|status|show)\s+\S+', 'systemctl'),
        (r'sysctl\s+\S+', 'sysctl'),
        (r'cat\s+/etc/\S+', 'cat'),
        (r'stat\s+\S+', 'stat'),
        (r'grep\s+[^\n|]+\s+/etc/\S+', 'grep config'),
        (r'rpm\s+-q\s+\S+', 'rpm'),
        (r'find\s+/\S+[^\n]+', 'find'),
    ]
    
    found_commands = set()
    for pattern, cmd_type in cmd_patterns:
        matches = re.findall(pattern, audit_procedure, re.IGNORECASE)
        for cmd in matches:
            cmd = cmd.strip()
            if len(cmd) > 5 and cmd not in found_commands:
                found_commands.add(cmd)
                
                if 'systemctl' in cmd:
                    rationale = "PASS when service is in expected state (enabled/disabled/active/inactive as required), FAIL otherwise"
                elif 'sysctl' in cmd:
                    rationale = "PASS when parameter value matches expected setting, FAIL otherwise"
                elif 'find' in cmd:
                    rationale = "PASS when no unexpected files found (empty output), FAIL when files are found"
                elif 'rpm' in cmd:
                    rationale = "PASS when package is installed/not installed as required, FAIL otherwise"
                else:
                    rationale = "PASS when output matches expected value, FAIL otherwise"
                
                requirements.append(f"Execute audit command: `{cmd}`. Rationale: {rationale}")
    
    # Pattern 5: Add verify statements with cross-reference logic based on other requirements
    if module_name:
        # req_4: Module not available OR disabled
        # PASS when: req_1=PASS (module not found) OR req_3=PASS (properly blacklisted)
        requirements.append(
            f"Verify: the {module_name} kernel module is not available on the system or has been disabled. "
            f"Rationale: PASS when req_1=PASS (module not found on filesystem) OR req_3=PASS (module is blacklisted), "
            f"FAIL when req_1=FAIL AND req_3=FAIL (module exists and not blacklisted)"
        )
        
        # req_5: OVERALL COMPLIANCE - Module not loaded AND not loadable
        # PASS when: req_2=PASS (not loaded) AND (req_1=PASS (not available) OR req_3=PASS (blacklisted))
        requirements.append(
            f"OVERALL Verify: the {module_name} kernel module is not loaded and not loadable. "
            f"Rationale: PASS when req_2=PASS (module not loaded) AND (req_1=PASS (module not available) OR req_3=PASS (module blacklisted)), "
            f"FAIL when req_2=FAIL (module is loaded) OR (req_1=FAIL AND req_3=FAIL) (module exists and not blacklisted)"
        )
    elif title:
        # Extract the key verification from title
        verify_text = title.replace('Ensure', '').replace('ensure', '').strip()
        if verify_text:
            requirements.append(
                f"Verify: {verify_text}. Rationale: PASS when all audit checks pass, FAIL otherwise"
            )
    
    # Remove duplicates while preserving order
    seen = set()
    unique_requirements = []
    for req in requirements:
        # Create a simplified key for deduplication
        key = re.sub(r'\s+', ' ', req.lower()[:100])
        if key not in seen:
            seen.add(key)
            unique_requirements.append(req)
    
    return unique_requirements


def generate_playbook_requirements_from_checkpoint(checkpoint_info: dict) -> dict:
    """
    Generate playbook requirements based on CIS checkpoint info.
    
    First attempts to extract requirements directly from the audit procedure,
    then uses DeepSeek AI to enhance/format them.
    
    Args:
        checkpoint_info: Dict containing checkpoint details
        
    Returns:
        dict: {
            'objective': str,
            'requirements': list[str]
        }
    """
    from langchain_openai import ChatOpenAI
    from langchain_core.prompts import ChatPromptTemplate
    
    checkpoint_id = checkpoint_info.get('checkpoint_id', 'Unknown')
    title = checkpoint_info.get('title', '')
    
    # Get raw agent response if available (this contains the full details from agent search)
    raw_agent_response = checkpoint_info.get('raw_agent_response', '')
    audit_procedure = checkpoint_info.get('audit_procedure', '')
    
    # FIRST: Try to extract requirements directly from audit procedure
    # Use raw_agent_response if audit_procedure is not available (it contains the full audit details)
    source_text = audit_procedure if audit_procedure and len(audit_procedure) > 100 else raw_agent_response
    
    extracted_requirements = extract_audit_steps_from_procedure(source_text, checkpoint_id, title)
    
    if extracted_requirements and len(extracted_requirements) >= 2:
        print(f"    ‚úÖ Extracted {len(extracted_requirements)} audit requirements directly from audit procedure")
        for i, req in enumerate(extracted_requirements[:3], 1):
            preview = req[:100] + '...' if len(req) > 100 else req
            print(f"       {i}. {preview}")
        if len(extracted_requirements) > 3:
            print(f"       ... and {len(extracted_requirements) - 3} more")
        
        return {
            'objective': f"Audit CIS checkpoint {checkpoint_id}: {title}" if title else f"Audit CIS checkpoint: {checkpoint_id}",
            'requirements': extracted_requirements
        }
    
    print(f"    ‚ö†Ô∏è Could not extract requirements directly, using LLM generation...")
    
    # FALLBACK: Use LLM to generate requirements
    llm = ChatOpenAI(
        model="deepseek-chat",
        api_key=os.getenv("DEEPSEEK_API_KEY"),
        base_url="https://api.deepseek.com",
        temperature=0
    )
    
    # Build the prompt - include raw agent response if we have it
    additional_context = ""
    if raw_agent_response:
        additional_context = f"""
**Full Agent Response (contains complete checkpoint details):**
{raw_agent_response[:6000]}
"""
    
    prompt_template = """You are an expert system administrator creating Ansible playbooks for CIS benchmark compliance auditing.

Based on the following CIS checkpoint information, generate:
1. A clear playbook objective (one sentence) focused on AUDITING this security control
2. A list of 3-8 specific requirements for an Ansible playbook

**CIS Checkpoint Information:**
- Checkpoint ID: {checkpoint_id}
- Title: {title}
- Profile Applicability: {profile_applicability}
- Description: {description}
- Rationale: {rationale}

**Audit Procedure from CIS Benchmark:**
{audit_procedure}

**Remediation Procedure from CIS Benchmark:**
{remediation_procedure}
{additional_context}
**Task:**
Generate Ansible playbook requirements that will:
1. AUDIT the system to check if it complies with this CIS checkpoint
2. COLLECT the current system state/configuration
3. COMPARE against the expected values from CIS benchmark
4. REPORT compliance status (PASS/FAIL) with details

**Output Format:**
Return ONLY a valid JSON object with this exact structure (no markdown, no code blocks):
{{
    "objective": "Audit CIS checkpoint {checkpoint_id}: {title}",
    "requirements": [
        "Check <condition> using command: `<command>`. Rationale: PASS when <expected result>, FAIL when <failure condition>",
        "Verify <setting> with command: `<command>`. Rationale: PASS when <expected>, FAIL otherwise",
        "Run the following audit script to check <module>: ```#!/usr/bin/env bash\\n<full script content here>```. Rationale: PASS when <condition>, FAIL when <condition>",
        ...
    ]
}}

**Script Inclusion Example:**
If the audit procedure contains a script like:
  #!/usr/bin/env bash
  l_output="" l_output2=""
  ...
You MUST include the ENTIRE script in the requirement, like:
  "Run the following audit script to verify kernel module availability: ```#!/usr/bin/env bash\\nl_output=\"\" l_output2=\"\"\\n...full script...```. Rationale: PASS when script output shows module not available, FAIL otherwise"

**Important Guidelines:**
- Base requirements DIRECTLY on the audit procedure commands from the checkpoint information
- Include the exact commands from the CIS benchmark audit procedure
- Focus on AUDITING (checking compliance), not remediation
- Each requirement should map to a specific audit step
- CRITICAL: Each requirement MUST end with "Rationale: PASS when <condition>, FAIL when <condition>" explaining the pass/fail logic
- Include expected values/outputs for comparison
- If the Full Agent Response is provided, extract the audit commands from there
- CRITICAL: If the audit procedure contains a SCRIPT (bash script, shell script), you MUST include the FULL script content in the requirement, NOT just "use the provided script". The requirement must be SELF-CONTAINED with all script details.
- When including scripts, format them as: "Run the following script: ```<full script content>```"
- Never reference "the audit script" or "the provided script" without including the actual script code

Generate the JSON now:"""

    prompt = ChatPromptTemplate.from_template(prompt_template)
    chain = prompt | llm
    
    response = chain.invoke({
        'checkpoint_id': checkpoint_info.get('checkpoint_id', 'Unknown'),
        'title': checkpoint_info.get('title', '') or 'Unknown',
        'profile_applicability': checkpoint_info.get('profile_applicability', '') or 'Not specified',
        'description': checkpoint_info.get('description', '') or 'Not specified',
        'additional_context': additional_context,
        'rationale': checkpoint_info.get('rationale', '') or 'See Full Agent Response above',
        'audit_procedure': checkpoint_info.get('audit_procedure', '') or 'See Full Agent Response above',
        'remediation_procedure': checkpoint_info.get('remediation_procedure', '') or 'See Full Agent Response above'
    })
    
    response_text = response.content.strip()
    
    # Clean up response
    if "```json" in response_text:
        response_text = response_text.split("```json")[1].split("```")[0].strip()
    elif "```" in response_text:
        response_text = response_text.split("```")[1].split("```")[0].strip()
    
    try:
        result = json.loads(response_text)
        return result
    except json.JSONDecodeError as e:
        print(f"Warning: Failed to parse JSON response: {e}")
        # Build better fallback requirements using available checkpoint info
        checkpoint_id = checkpoint_info.get('checkpoint_id', 'Unknown')
        title = checkpoint_info.get('title', '')
        audit_proc = checkpoint_info.get('audit_procedure', '')
        raw_response = checkpoint_info.get('raw_agent_response', '')
        
        # Try to extract key audit commands from audit procedure or raw response
        source_text = audit_proc if audit_proc and len(audit_proc) > 50 else raw_response
        fallback_requirements = []
        
        if source_text:
            import re
            # Look for shell commands in the source text
            cmd_patterns = [
                r'(?:Run|Execute|Use)[:\s]+[`\'"]?([^`\'"]+(?:lsmod|modprobe|find|grep|cat|ls|systemctl|sysctl)[^`\'"]*)[`\'"]?',
                r'#\s*([a-z/]+\s+[^\n]+)',  # Commands starting with #
                r'```(?:bash|shell)?\n([^`]+)```',  # Code blocks
            ]
            
            for pattern in cmd_patterns:
                matches = re.findall(pattern, source_text, re.IGNORECASE)
                for match in matches[:5]:  # Limit to 5 commands
                    cmd = match.strip()
                    if len(cmd) > 10 and len(cmd) < 200:
                        fallback_requirements.append(f"Execute audit command: `{cmd}`. Rationale: PASS when command shows compliant state, FAIL otherwise")
        
        # If no commands found, use generic but more specific requirements
        if not fallback_requirements:
            if title:
                fallback_requirements.append(f"Verify that: {title}. Rationale: PASS when verified, FAIL otherwise")
            fallback_requirements.extend([
                f"Check system configuration for CIS {checkpoint_id}. Rationale: PASS when compliant, FAIL otherwise",
                "Collect audit evidence and system state. Rationale: PASS when data collected, FAIL otherwise"
            ])
        
        return {
            'objective': f"Audit CIS checkpoint {checkpoint_id}: {title}" if title else f"Audit CIS checkpoint: {checkpoint_id}",
            'requirements': fallback_requirements
        }


def run_playbook_generation(objective, requirements, target_host, test_host, become_user, filename, skip_execution=True, audit_procedure=None):
    """
    Call langgraph_deepseek_generate_playbook.py to generate and execute the playbook.
    
    Args:
        objective: Playbook objective
        requirements: List of requirements
        target_host: Target host for execution
        test_host: Test host for validation
        become_user: User to become
        filename: Output filename
        skip_execution: If True, skip playbook execution
        audit_procedure: CIS Benchmark audit procedure (script/commands)
    """
    print("\n" + "="*100)
    if skip_execution:
        print("üîß Calling langgraph_deepseek_generate_playbook.py to GENERATE playbook (no execution)...")
    else:
        print("üöÄ Calling langgraph_deepseek_generate_playbook.py to generate and execute playbook...")
    print("="*100)
    
    max_retries = max(len(requirements), 3)
    print(f"Max retries: {max_retries} (based on {len(requirements)} requirements)")
    
    cmd = [
        'python3',
        'langgraph_deepseek_generate_playbook.py',
        '--objective', objective,
        '--target-host', target_host,
        '--become-user', become_user,
        '--filename', filename,
        '--max-retries', str(max_retries)
    ]
    
    if test_host and test_host != target_host:
        cmd.extend(['--test-host', test_host])
    
    # Add audit procedure if provided
    if audit_procedure:
        cmd.extend(['--audit-procedure', audit_procedure])
    
    for req in requirements:
        cmd.extend(['--requirement', req])
    
    # Display full command
    print(f"\nüìç Full Command:")
    print("="*100)
    print("python3 langgraph_deepseek_generate_playbook.py \\")
    print(f"  --objective '{objective}' \\")
    print(f"  --target-host {target_host} \\")
    if test_host and test_host != target_host:
        print(f"  --test-host {test_host} \\")
    print(f"  --become-user {become_user} \\")
    print(f"  --filename {filename} \\")
    print(f"  --max-retries {max_retries} \\")
    if audit_procedure:
        # Show truncated audit procedure in command display
        audit_preview = audit_procedure[:100].replace('\n', '\\n') + ('...' if len(audit_procedure) > 100 else '')
        print(f"  --audit-procedure '{audit_preview}' \\")
    for idx, req in enumerate(requirements, 1):
        if idx < len(requirements):
            print(f"  --requirement '{req}' \\")
        else:
            print(f"  --requirement '{req}'")
    print("="*100)
    print()
    
    try:
        result = subprocess.run(
            cmd,
            capture_output=False,
            text=True,
            timeout=1200,
            env=os.environ  # Pass environment to subprocess so it can find Python and its venv
        )
        
        return result.returncode == 0, "Playbook generation completed"
        
    except subprocess.TimeoutExpired:
        return False, "Playbook generation timed out after 20 minutes"
    except Exception as e:
        return False, f"Error running playbook generation: {str(e)}"


# =============================================================================
# Interactive Mode
# =============================================================================

def interactive_mode(vector_store, args):
    """Interactive mode to query CIS checkpoints and generate playbooks."""
    print("\n" + "="*70)
    print("CIS RHEL 8 Checkpoint to Ansible Playbook Generator")
    print("="*70)
    print("\nEnter CIS checkpoint IDs to generate audit playbooks.")
    print("Examples:")
    print("  - 1.1.1.1")
    print("  - 1.1.1.1 Ensure cramfs kernel module is not available")
    print("  - 5.2.1 Ensure permissions on /etc/ssh/sshd_config are configured")
    print("\nType 'quit' or 'exit' to stop.\n")
    
    while True:
        try:
            checkpoint = input("Enter checkpoint (or 'quit'): ").strip()
            
            if not checkpoint:
                continue
            
            if checkpoint.lower() in ['quit', 'exit', 'q']:
                print("\nGoodbye!")
                break
            
            process_checkpoint(vector_store, checkpoint, args)
            
        except KeyboardInterrupt:
            print("\n\nInterrupted. Goodbye!")
            break
        except Exception as e:
            print(f"\nError: {e}\n")


def process_checkpoint(vector_store, checkpoint: str, args):
    """Process a single CIS checkpoint and generate playbook."""
    
    verbose = getattr(args, 'verbose', False)
    
    # Step 1 & 2 Combined: Use Agent-based RAG to get checkpoint info (like cis_rhel8_rag_deepseek.py)
    print("\n" + "="*100)
    print(f"STEP 1: Querying CIS RHEL 8 Benchmark using Agent RAG for: '{checkpoint}'")
    print("="*100)
    print("Using agent-based search (same approach as cis_rhel8_rag_deepseek.py)...")
    
    # Use agent to get checkpoint info - this works better than direct search
    agent_response = get_checkpoint_info_with_agent(vector_store, checkpoint, verbose=verbose)
    
    # Step 2: Parse the agent response into structured format
    print("\n" + "="*100)
    print("STEP 2: Parsing checkpoint information from agent response")
    print("="*100)
    
    checkpoint_info = parse_agent_response_to_checkpoint_info(checkpoint, agent_response)
    
    print(f"\nüìã CIS Checkpoint Details:")
    print("-"*100)
    print(f"ID: {checkpoint_info.get('checkpoint_id', 'N/A')}")
    print(f"Title: {checkpoint_info.get('title', 'N/A') or 'See agent response below'}")
    print(f"Profile: {checkpoint_info.get('profile_applicability', 'N/A') or 'See agent response below'}")
    print(f"\nDescription: {checkpoint_info.get('description', 'N/A') or 'See agent response below'}")
    print(f"\nRationale: {checkpoint_info.get('rationale', 'N/A') or 'See agent response below'}")
    
    # Check if we have parsed audit procedure or need to show raw response
    audit_proc = checkpoint_info.get('audit_procedure', '')
    remed_proc = checkpoint_info.get('remediation_procedure', '')
    raw_response = checkpoint_info.get('raw_agent_response', '')
    
    if audit_proc:
        print("\n" + "-"*100)
        print("üîç AUDIT PROCEDURE:")
        print("-"*100)
        if len(audit_proc) > 2000:
            print(audit_proc[:2000] + "\n... (truncated)")
        else:
            print(audit_proc)
    
    if remed_proc:
        print("\n" + "-"*100)
        print("üîß REMEDIATION PROCEDURE:")
        print("-"*100)
        if len(remed_proc) > 2000:
            print(remed_proc[:2000] + "\n... (truncated)")
        else:
            print(remed_proc)
    
    # If parsing didn't extract key fields, show the full agent response
    if raw_response or (not audit_proc and not remed_proc):
        print("\n" + "-"*100)
        print("üìù FULL AGENT RESPONSE (use this for requirements):")
        print("-"*100)
        response_to_show = raw_response or agent_response
        if len(response_to_show) > 4000:
            print(response_to_show[:4000] + "\n... (truncated)")
        else:
            print(response_to_show)
        # Store the agent response in checkpoint_info for use in requirements generation
        checkpoint_info['raw_agent_response'] = response_to_show
    print("-"*100)
    
    # Step 3: Generate playbook requirements
    print("\n" + "="*100)
    print("STEP 3: Generating playbook requirements using DeepSeek AI")
    print("="*100)
    
    playbook_spec = generate_playbook_requirements_from_checkpoint(checkpoint_info)
    
    objective = playbook_spec.get('objective', '')
    requirements = playbook_spec.get('requirements', [])
    
    print(f"\nüìã Generated Playbook Specification:")
    print("-"*100)
    print(f"Objective: {objective}")
    print(f"\nRequirements ({len(requirements)} items):")
    for idx, req in enumerate(requirements, 1):
        print(f"  {idx}. {req}")
    print("-"*100)
    
    # Interactive requirement review (unless --no-interactive)
    if not args.no_interactive:
        print("\n" + "="*100)
        print("üìù REQUIREMENT REVIEW AND FEEDBACK")
        print("="*100)
        print("Options:")
        print("  1. Press ENTER to generate playbook")
        print("  2. Type 'add' to add new requirements")
        print("  3. Type 'edit N' to edit requirement N")
        print("  4. Type 'delete N' to delete requirement N")
        print("  5. Type 'skip' to skip playbook generation")
        print("  6. Type 'help' for more commands")
        print("="*100)
        
        while True:
            user_input = input("\nüë§ Your action (ENTER to generate, 'skip' to skip): ").strip()
            
            if not user_input:
                print("\n‚úÖ Generating playbook...")
                break
            
            if user_input.lower() == 'skip':
                print("\n‚è≠Ô∏è  Skipping playbook generation for this checkpoint")
                return
            
            if user_input.lower() == 'done':
                print("\nüìã Updated Requirements ({} items):".format(len(requirements)))
                for idx, req in enumerate(requirements, 1):
                    print(f"  {idx}. {req}")
                continue
            
            if user_input.lower() == 'add':
                new_req = input("   Enter new requirement: ").strip()
                if new_req:
                    requirements.append(new_req)
                    print(f"   ‚úÖ Added requirement {len(requirements)}: {new_req}")
                continue
            
            if user_input.lower().startswith('edit '):
                try:
                    req_num = int(user_input.split()[1])
                    if 1 <= req_num <= len(requirements):
                        print(f"   Current: {requirements[req_num-1]}")
                        new_text = input("   New text: ").strip()
                        if new_text:
                            requirements[req_num-1] = new_text
                            print(f"   ‚úÖ Updated requirement {req_num}")
                    else:
                        print(f"   ‚ùå Invalid number. Must be 1-{len(requirements)}")
                except (ValueError, IndexError):
                    print("   ‚ùå Invalid format. Use: edit N")
                continue
            
            if user_input.lower().startswith('delete '):
                try:
                    req_num = int(user_input.split()[1])
                    if 1 <= req_num <= len(requirements):
                        deleted = requirements.pop(req_num-1)
                        print(f"   ‚úÖ Deleted: {deleted}")
                    else:
                        print(f"   ‚ùå Invalid number. Must be 1-{len(requirements)}")
                except (ValueError, IndexError):
                    print("   ‚ùå Invalid format. Use: delete N")
                continue
            
            if user_input.lower() == 'help':
                print("\nüìñ Commands: ENTER (generate), skip, add, edit N, delete N, done (show reqs)")
                continue
            
            print("   ‚ùå Unknown command. Type 'help' for options.")
    
    # Add CIS reference to requirements
    checkpoint_id = checkpoint_info.get('checkpoint_id', checkpoint)
    requirements.append(f"Add comment referencing CIS RHEL 8 Benchmark v4.0.0, checkpoint {checkpoint_id}")
    requirements.append(f"""Create a task named 'Generate compliance report' that displays a debug msg with this EXACT format:
========================================================
        COMPLIANCE REPORT - CIS {checkpoint_id}
========================================================
Reference: CIS RHEL 8 Benchmark v4.0.0 checkpoint {checkpoint_id}
========================================================

REQUIREMENT 1 - <requirement description>:
  Task: <task name>
  Command: <command executed>
  Exit code: <exit code>
  Data: <command output>
  Status: PASS or FAIL
  Rationale: <why PASS or FAIL based on the requirement's rationale>

(repeat for each requirement)

========================================================
OVERALL COMPLIANCE:
  Result: PASS or FAIL
  Rationale: <overall pass/fail logic explanation>
========================================================

Each requirement MUST have Status and Rationale lines. The OVERALL COMPLIANCE section is REQUIRED at the end.""")
    requirements.append("CRITICAL: Use ignore_errors: true and failed_when: false on all audit tasks so all checks complete and report status")
    
    # Step 4: Generate playbook filename
    safe_checkpoint_id = checkpoint_id.replace('.', '_').replace(' ', '_')[:20]
    filename = args.filename if args.filename else f"cis_audit_{safe_checkpoint_id}.yml"
    
    # Step 5: Generate and optionally execute playbook
    print("\n" + "="*100)
    print("STEP 4: Generating Ansible Playbook")
    print("="*100)
    print(f"Target Host:    {args.target_host}")
    print(f"Become User:    {args.become_user}")
    print(f"Output File:    {filename}")
    
    # Get the audit procedure from checkpoint info
    # Priority: 1) parsed audit_procedure, 2) raw_agent_response (contains full details)
    audit_procedure = checkpoint_info.get('audit_procedure', '')
    raw_response = checkpoint_info.get('raw_agent_response', '')
    
    # If audit_procedure is empty or generic, try to extract from raw_agent_response
    if not audit_procedure or audit_procedure in ['Not specified', 'See Full Agent Response above', 'N/A', '']:
        if raw_response:
            # Try multiple patterns to extract audit procedure
            import re
            audit_patterns = [
                # Pattern 1: **Audit:** or **Audit Procedure:** section
                r'\*\*Audit(?:\s+Procedure)?\*\*[:\s]*\n?(.*?)(?=\*\*(?:Remediation|Impact|Default|References)|\n\n\*\*|$)',
                # Pattern 2: Audit: or Audit Procedure: section  
                r'(?:Audit|AUDIT)(?:\s+Procedure)?[:\s]*\n(.*?)(?=(?:Remediation|REMEDIATION|Impact|IMPACT|Default|DEFAULT|References|$))',
                # Pattern 3: numbered section like "6. Audit procedure"
                r'\d+\.\s*(?:Audit|AUDIT)[^\n]*\n(.*?)(?=\d+\.\s*(?:Remediation|Impact)|$)',
            ]
            
            for pattern in audit_patterns:
                audit_match = re.search(pattern, raw_response, re.DOTALL | re.IGNORECASE)
                if audit_match and len(audit_match.group(1).strip()) > 50:
                    audit_procedure = audit_match.group(1).strip()
                    break
            
            # If still no audit procedure found, use the FULL raw_agent_response
            # This contains all the checkpoint details including audit commands
            if not audit_procedure or len(audit_procedure) < 50:
                # The raw_agent_response contains the complete checkpoint info
                # which the LLM can use to understand what needs to be audited
                audit_procedure = raw_response
                print(f"    Using full agent response as audit context ({len(audit_procedure)} chars)")
    
    if audit_procedure and len(audit_procedure) > 50:
        print(f"Audit Proc:     {len(audit_procedure)} chars (CIS Benchmark audit procedure will be used)")
        # Show a preview of the audit procedure
        preview_lines = audit_procedure[:500].split('\n')[:5]
        for line in preview_lines:
            if line.strip():
                print(f"                {line[:80]}{'...' if len(line) > 80 else ''}")
        if len(audit_procedure) > 500:
            print(f"                ... ({len(audit_procedure) - 500} more chars)")
    else:
        print(f"Audit Proc:     Not available (using requirements only)")
    
    if args.skip_execution:
        print("‚ö†Ô∏è  Execution will be SKIPPED (--skip-execution flag)")
    
    # audit_procedure was already extracted above in Step 4
    success, output = run_playbook_generation(
        objective=objective,
        requirements=requirements,
        target_host=args.target_host,
        test_host=args.test_host if args.test_host else args.target_host,
        become_user=args.become_user,
        filename=filename,
        skip_execution=args.skip_execution,
        audit_procedure=audit_procedure if audit_procedure and len(audit_procedure) > 50 else None
    )
    
    # Summary
    print("\n" + "="*100)
    print("üìä SUMMARY")
    print("="*100)
    
    if success:
        print(f"‚úÖ Successfully generated audit playbook!")
        print(f"\nüìã CIS Checkpoint: {checkpoint_info.get('checkpoint_id', checkpoint)}")
        print(f"üìÑ Title: {checkpoint_info.get('title', 'N/A')}")
        print(f"üìÅ Playbook: {filename}")
        print(f"üéØ Target: {args.target_host}")
    else:
        print(f"‚ùå Playbook generation failed: {output}")


# =============================================================================
# Main
# =============================================================================

def main():
    parser = argparse.ArgumentParser(
        description='Generate Ansible audit playbooks from CIS RHEL 8 checkpoints',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Interactive mode
  python3 cis_checkpoint_to_playbook.py
  
  # Single checkpoint
  python3 cis_checkpoint_to_playbook.py --checkpoint "1.1.1.1"
  
  # With custom target host
  python3 cis_checkpoint_to_playbook.py --checkpoint "1.1.1.1" --target-host 192.168.122.16
  
  # Skip execution (generate only)
  python3 cis_checkpoint_to_playbook.py --checkpoint "5.2.4" --skip-execution
"""
    )
    
    parser.add_argument(
        '--checkpoint', '-c',
        type=str,
        default=None,
        help='CIS checkpoint ID or description (e.g., "1.1.1.1" or "Ensure cramfs kernel module is not available")'
    )
    
    parser.add_argument(
        '--target-host', '-t',
        type=str,
        default='192.168.122.16',
        help='Target host for playbook execution (default: 192.168.122.16)'
    )
    
    parser.add_argument(
        '--test-host',
        type=str,
        default=None,
        help='Test host for validation before target execution'
    )
    
    parser.add_argument(
        '--become-user', '-u',
        type=str,
        default='root',
        help='User to become when executing tasks (default: root)'
    )
    
    parser.add_argument(
        '--filename', '-f',
        type=str,
        default=None,
        help='Output filename for the generated playbook (default: cis_audit_<checkpoint>.yml)'
    )
    
    parser.add_argument(
        '--skip-execution',
        action='store_true',
        help='Generate playbook but skip execution'
    )
    
    parser.add_argument(
        '--no-interactive',
        action='store_true',
        help='Skip interactive requirement review'
    )
    
    parser.add_argument(
        '--verbose', '-v',
        action='store_true',
        help='Show verbose output including raw search results for debugging'
    )
    
    args = parser.parse_args()
    
    try:
        # Load vector store
        print("\n" + "="*100)
        print("üîß Initializing CIS RHEL 8 Benchmark Vector Store")
        print("="*100)
        
        vector_store = load_or_create_vector_store()
        print("‚úÖ Vector store ready")
        
        if args.checkpoint:
            # Single checkpoint mode
            process_checkpoint(vector_store, args.checkpoint, args)
        else:
            # Interactive mode
            interactive_mode(vector_store, args)
            
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Interrupted by user")
        sys.exit(1)
    except Exception as e:
        print(f"\n‚ùå Error: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()

